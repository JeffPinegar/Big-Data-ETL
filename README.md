# Jeff Pinegar
jeffpinegar1@gmail.com<br>
717-982-0516

# Big-Data-ETL
Challenge 22 - Big data ETL <br>
In this assignment, we are using:
* Google Colab for running jupyter notebooks with Spark
* AWS - RDS Relational Database Services
* PySpark for data extraction, transformation and loading Postgress
* Postgres 

## Summary

This exercise was focused on Big Data ETL (Extract, Transform and Load).  It is similar to previous exercises with ETL; however, in this exercise, we were using “Big Data.”  By one definition big data has more than 1M records.  These data sets had more than 1.5M records.  To tackle this task, cloud-based tools were used/required.  For example, it is not possible to load this data into Excel.

## Files in folder part-1

* part_one_tools.ipynb <br>
Jupyter Notebook used to perform ETL on the file “amazon_reviews_us_Tools_v1_00”
* part_one_tools.ipynb - Colaboratory.pdf<br> 
This is a PDF printout following the successful execution of all the code of part_one_tools.ipynb in Google Colaboratory
* part_one_cameras.ipynb <br>
Jupyter Notebook used to perform ETL on the file “amazon_reviews_us_Camera_v1_00”
* part_one_cameras.ipynb - Colaboratory.pdf<br>
This is a PDF printout following the successful execution of all the code of part_one_cameras.ipynb in Google Colaboratory

* Tools Loaded.png<br>
Image of the Colaboratory notebook showing the execution time for loading the Tools database.

